{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, InputLayer, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.metrics import AUC\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'set_random_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5722e23c6bb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# 4. Set `tensorflow` pseudo-random generator at a fixed value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# 5. For layers that introduce randomness like dropout, make sure to set seed values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'set_random_seed'"
     ]
    }
   ],
   "source": [
    "#Set random seed\n",
    "\n",
    "# Set a seed value\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "# 5. For layers that introduce randomness like dropout, make sure to set seed values \n",
    "#model.add(Dropout(0.25, seed=seed_value))\n",
    "\n",
    "#6 Configure a new global `tensorflow` session\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of image data (train, validation, and test) with data augmentation\n",
    "\n",
    "## Set file paths to image files\n",
    "project_path = \"/Users/hellojenny/Metis/Metis-Bootcamp/Projects/Project 5 - Image Prediction using CNN\"\n",
    "train_path = project_path + \"/chest_xray/train/\"\n",
    "val_path = project_path + \"/chest_xray/val/\"\n",
    "test_path = project_path + \"/chest_xray/test/\"\n",
    "\n",
    "## Set up hyperparameters that will be used later\n",
    "hyper_dimension = 64\n",
    "hyper_batch_size = 128\n",
    "hyper_epochs = 100\n",
    "hyper_channels = 1\n",
    "hyper_mode = 'grayscale'\n",
    "\n",
    "## Generate batches of image data (train, validation, and test) with data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0) \n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory = train_path, \n",
    "                                                    target_size = (hyper_dimension, hyper_dimension),\n",
    "                                                    batch_size = hyper_batch_size, \n",
    "                                                    color_mode = hyper_mode,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    seed = 42)\n",
    "val_generator = val_datagen.flow_from_directory(directory = val_path, \n",
    "                                                 target_size = (hyper_dimension, hyper_dimension),\n",
    "                                                 batch_size = hyper_batch_size, \n",
    "                                                 class_mode = 'binary',\n",
    "                                                 color_mode = hyper_mode,\n",
    "                                                 shuffle=False,\n",
    "                                                 seed = 42)\n",
    "test_generator = test_datagen.flow_from_directory(directory = test_path, \n",
    "                                                 target_size = (hyper_dimension, hyper_dimension),\n",
    "                                                 batch_size = hyper_batch_size, \n",
    "                                                 class_mode = 'binary',\n",
    "                                                 color_mode = hyper_mode,\n",
    "                                                 shuffle=False,\n",
    "                                                 seed = 42)\n",
    "\n",
    "test_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\n",
    "\n",
    "cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(activation='relu', units=128))\n",
    "cnn.add(Dense(activation='sigmoid', units=1))\n",
    "\n",
    "cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=[AUC()])\n",
    "cnn_model = cnn.fit_generator(train_generator, \n",
    "                              steps_per_epoch = len(train_generator), \n",
    "                              epochs = 200, \n",
    "                              validation_data = val_generator,\n",
    "                              validation_steps = len(val_generator), \n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a function that outputs metrics and charts\n",
    "Metrics: Accuracy, Precision, Recall, Specificity, and F1 Score\n",
    "Charts:\n",
    "1) Train VS. Validation Loss\n",
    "2) Train VS. Validation AUC\n",
    "3) Confusion Matrix\n",
    "\"\"\" \n",
    "\n",
    "def create_charts(cnn, cnn_model):\n",
    "    ## DEFINE ##\n",
    "    ## Define 1:  train & validation loss\n",
    "    train_loss = cnn_model.history['loss']\n",
    "    val_loss = cnn_model.history['val_loss']\n",
    "    \n",
    "    ## Define 2: train & validation AUC\n",
    "    train_auc_name = list(cnn_model.history.keys())[3]\n",
    "    val_auc_name = list(cnn_model.history.keys())[1]\n",
    "    train_auc = cnn_model.history[train_auc_name]\n",
    "    val_auc = cnn_model.history[val_auc_name]\n",
    "    \n",
    "    ## Define 3: y_pred & y_true\n",
    "    y_true = test_generator.classes\n",
    "    Y_pred = cnn.predict_generator(test_generator, steps = len(test_generator))\n",
    "    y_pred = (Y_pred > 0.5).T[0]\n",
    "    y_pred_prob = Y_pred.T[0]\n",
    "    \n",
    "    ## PLOT ##\n",
    "    fig = plt.figure(figsize=(13, 10))\n",
    "    \n",
    "    ## PLOT 1: TRAIN VS. VALIDATION LOSS \n",
    "    plt.subplot(2,2,1)\n",
    "    plt.title(\"Training vs. Validation Loss\")\n",
    "    plt.plot(train_loss, label='training loss')\n",
    "    plt.plot(val_loss, label='validation loss')\n",
    "    plt.xlabel(\"Number of Epochs\", size=14)\n",
    "    plt.legend()\n",
    "\n",
    "    ## PLOT 2: TRAIN VS. VALIDATION AUC\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.title(\"Training vs. Validation AUC Score\")\n",
    "    plt.plot(train_auc, label='training auc')\n",
    "    plt.plot(val_auc, label='validation auc')\n",
    "    plt.xlabel(\"Number of Epochs\", size=14)\n",
    "    plt.legend()\n",
    "    \n",
    "    ## PLOT 3: CONFUSION MATRIX\n",
    "    plt.subplot(2,2,3)\n",
    "      # Set up the labels for in the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    names = ['True Negatives', 'False Positives', 'False Negatives', 'True Positives']\n",
    "    counts = ['{0:0.0f}'.format(value) for value in cm.flatten()]\n",
    "    percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(names, percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    ticklabels = ['Normal', 'Pneumonia']\n",
    "\n",
    "      # Create confusion matrix as heatmap\n",
    "    sns.set(font_scale = 1.4)\n",
    "    ax = sns.heatmap(cm, annot=labels, fmt='', cmap='Oranges', xticklabels=ticklabels, yticklabels=ticklabels )\n",
    "    plt.xticks(size=12)\n",
    "    plt.yticks(size=12)\n",
    "    plt.title(\"Confusion Matrix\") #plt.title(\"Confusion Matrix\\n\", fontsize=10)\n",
    "    plt.xlabel(\"Predicted\", size=14)\n",
    "    plt.ylabel(\"Actual\", size=14) \n",
    "    #plt.savefig('cm.png', transparent=True) \n",
    "    \n",
    "    ## PLOT 4: ROC CURVE\n",
    "    plt.subplot(2,2,4)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    auc = roc_auc_score(y_true, y_pred_prob)\n",
    "    plt.title('ROC Curve')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label = \"Random (AUC = 50%)\")\n",
    "    plt.plot(fpr, tpr, label='CNN (AUC = {:.2f}%)'.format(auc*100))\n",
    "    plt.xlabel('False Positive Rate', size=14)\n",
    "    plt.ylabel('True Positive Rate', size=14)\n",
    "    plt.legend(loc='best')\n",
    "    #plt.savefig('roc.png', bbox_inches='tight', pad_inches=1)\n",
    "    \n",
    "    ## END PLOTS\n",
    "    plt.tight_layout()\n",
    "    ;\n",
    "    \n",
    "    ## Summary Statistics\n",
    "    TN, FP, FN, TP = cm.ravel() # cm[0,0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "    accuracy = (TP + TN) / np.sum(cm) # % positive out of all predicted positives\n",
    "    precision = TP / (TP+FP) # % positive out of all predicted positives\n",
    "    recall =  TP / (TP+FN) # % positive out of all supposed to be positives\n",
    "    specificity = TN / (TN+FP) # % negative out of all supposed to be negatives\n",
    "    f1 = 2*precision*recall / (precision + recall)\n",
    "    stats_summary = '[Summary Statistics]\\nAccuracy = {:.2%} | Precision = {:.2%} | Recall = {:.2%} | Specificity = {:.2%} | F1 Score = {:.2%}'.format(accuracy, precision, recall, specificity, f1)\n",
    "    print(stats_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output results via metrics and charts\n",
    "\n",
    "create_charts(cnn, cnn_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
